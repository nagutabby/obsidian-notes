---
title: 2025年6月28日
---
## 今週の活動
- OpenStaticAnalyzerのビルド
	- https://github.com/sed-inf-u-szeged/OpenStaticAnalyzer
	- READMEを読むとWindowsとLinuxに対応しているらしい
	- どちらの環境でもビルドできなかった
- BugHunterデータセットに新たなレコードを追加するための別の方法を考える
	- 予測性能向上にほとんど貢献しないカラム（特徴量）を削除
		- カラム数を削減した上で代替ツールを探す
- バグの混入による保守性の低下を防ぐための方法を整理
	- バグ混入コミットをプッシュする直前でバグの有無の予測（難易度: 高）
		- バグ混入コミットとバグ修正コミットに加えて、バグとは無関係なコミットもデータセットに加える必要が生じ、ノイズが大きくなるため予測精度が下がる
	- バグ混入コミットとバグ修正コミットを集め、スプリント後にバグの原因を分析（難易度: 低）
		- 最小限のコミットデータからバグの原因を分析できるため、ノイズが小さい
- ソフトウェアメトリクスの値と各コミットのバグの有無の関係性を分析
	- Permutation Importance
		- 各特徴量をランダムに並び替えた際のモデル性能の低下を測定
		- モデルがどの特徴量を重視するかを知るのに適している
	- Pertial Dependence Plot
		- ターゲット変数との関係を知りたい特徴量以外の全ての特徴量の値を固定し、それぞれのデータに対して予測を行い、予測結果の平均値を算出した後、モデルの予測値と平均値の関係を可視化
		- 特定の特徴量と予測値の間の平均的な関係を知るのに適している
	- LIME（Local Interpretable Model-agnostic Explanations）
		- 単一データの近傍データを生成し、線形モデルを学習することで各特徴量の重要度（係数）を求める
		- 単一データの各特徴量が予測にどれくらい貢献したかを知るのに適しているが、特徴量間の相互作用を考慮しない
			- 複数の特徴量の組み合わせによって精度が大きく変わる場合にそれを捉えられない
	- SHAP（SHapley Additive exPlanations）
		- 協力ゲーム理論のシャープレイ値（Shapley Value）を機械学習モデルの説明に応用した手法
		- 各特徴量が予測にどれくらい貢献したかを知るのに適しており、特徴量間の相互作用を考慮する
## 得られた成果
- OpenStaticAnalyzerが利用できないため、バグとは無関係なコミットデータなどの新たなレコードを追加するには時間がかかる
- 機械学習モデルの改善も前回までの調査で難しいことが分かっているため、今後は主に特徴量エンジニアリング（特徴量の増加）によるバグの有無の予測精度を試みる
- 予測精度が向上すれば、保守性にかかわる問題があるかどうかをより明確に判断できるようになる
## 直面した課題
- 特徴量エンジニアリングのためのツール選定
	- まずはPythonとの相性がいいlizardという静的解析ツールを使い、新たなソフトウェアメトリクスを収集
## 来週の計画
- 特徴量エンジニアリングのためのプログラムの作成