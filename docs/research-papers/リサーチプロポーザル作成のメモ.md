# リサーチプロポーザル作成のメモ
## パターン検出に活用できる異常検出アルゴリズム
### Zスコア
- 概要
	- データポイントが平均からどれだけ標準偏差単位で離れているかを測定
- アルゴリズム
	- データの平均μと標準偏差σを計算
	- それぞれのデータポイントxについて Z = (z - μ) / σ を計算
	- |Z| > しきい値 の場合に、そのポイントを異常と判定
- 特徴
	- 正規分布に従うデータに適している
	- 移動平均と組み合わせることで時系列データに応用できる
	- 平均と標準偏差自体が外れ値の影響を受けるため、外れ値に弱い
### CUSUM (Cumulative Sum, 累積和)
- 概要
	- 時系列データにおける小さな変化を検出するための逐次分析手法
	- データの累積偏差を追跡し、それが特定のしきい値を超えると変化点として検出
- アルゴリズム
	- 基準値 (通常は平均) からの偏差を計算
	- これらの偏差の上方向と下方向の累積和を追跡
	- 累積和が設定されたしきい値を超えた場合に、変化点 (異常) を検出
- 特徴
	- 時系列データの微小な変化の検出に優れている
	- トレンドの変化点を特定できる
	- パラメーター設定 (感度としきい値) の調整が必要
### Isolation Forest
- 概要
	- 教師なし学習の異常検出アルゴリズム
	- データを再帰的に分割する決定木を用いて異常値を検出
	- 正常データが多い領域では分割に多くのステップが必要になる一方で、異常値は少ないステップで分離できるという原理に基づいている
- アルゴリズム
	- データセットから複数のサブサンプルを作成
	- それぞれのサブサンプルに対して決定木を構築
		- ランダムな特徴を選び、ランダムな分割点でデータを二分
		- 各点が単独になるか、指定された深さに達するまでに再帰的に分割
	- ポイントの異常スコアは、それを分離するのに必要な平均パス長に基づいて計算
		- パス長が短い = 異常値の可能性が高い
- 特徴
	- 高次元データに効果的
	- 線形時間の複雑性を持つため、計算効率が高い
	- 明示的な密度推定が不要
### Local Outlier Factor (LOF)
- 概要
	- 密度ベースの、教師なし学習の異常検出アルゴリズム
	- データポイントの局所的な密度を周囲の近傍点の密度と比較することで異常を検出
	- それぞれのポイントに局所的外れ値因子を割り当て、周囲と比べて密度が著しく低いポイントを異常として特定
- アルゴリズム
	- それぞれのデータポイントpについて、k近傍を特定
	- それぞれのポイントの到達可能距離を計算
		- ポイントpからポイントoへの到達可能距離
		- k-distanceは、ポイントとそのポイントとk番目に近いポイントとの距離
	- それぞれのポイントの局所到達可能密度 (LRD) を計算
	- 最終的なLOFスコアを計算
		- LOFスコアが1より大きいほど、異常である可能性が高い
- 特徴
	- 局所的密度の違いに基づいて以上を検出できるため、様々な密度のクラスターが混在するデータセットでも効果的
	- 単一のグローバルなしきい値に依存しない
	- 大規模データセットの場合は計算コストが高い
	- パラメーターkの選択が結果に大きく影響
### One-Class SVM
- 概要
	- 教師なし学習の異常検出手法
	- 正常データのみを使用して学習し、それ以外を異常として検出
	- データを高次元空間に写像し、データの大部分を含む最小の超平面を見つけることで、その境界外のデータを異常として識別
- アルゴリズム
	- カーネル関数を用いてデータを高次元特徴空間に写像
	- 原点からデータポイントを最大限に分離する超平面を学習
	- 決定関数：f(x) = sgn((w・Φ(x)) - ρ)
	    - Φ(x)は高次元空間への写像
	    - wは超平面の法線ベクトル
	    - ρはバイアス項
	- f(x) < 0 となるポイントを異常と判定
- 特徴
	- 高次元データや複雑な分布を持つデータに効果的
	- パラメーター調整が必要
	- 訓練データに異常値が含まれると性能が低下
	- 大規模データセットの場合は計算コストが高い
## データ収集・分析に活用できるツール
### PyDriller
- Gitリポジトリのマイニングに特化したPythonフレームワーク
- コミット、変更、開発者情報などを抽出する機能を提供
- メソッドレベルの変更追跡やAST解析ができる
### GrimoireLab
- ソフトウェア開発リポジトリ (GitHub, GitLabなど) からデータを収集し、データ分析・可視化を行える
- リポジトリからデータを取得し、データベースに保存
- メトリクスを計算し、プロジェクトの健全性や進捗状況を監視
### CodeShovel
- コードの変更履歴を詳細に追跡・分析
- 特に、関数やメソッドの進化 (作成、変更、削除など) をリポジトリ全体の履歴を通じて調査するために設計されている
### SonarQube
- コード品質の向上を目的とした静的コード解析ツール
- バグや脆弱性の検出、コーディング規約違反の特定、コードの重複率の計測、コードの複雑度の分析などの機能を提供
### GitHub API + PyGithub
- GitHubリポジトリのメタデータ、イシュー、PRの詳細の取得
- スターやフォークなどのプロジェクト人気度メトリクスの取得
### scikit-learn
- 異常検出アルゴリズムの実装
- 機械学習モデルの構築と評価

# 議事録
- 技術的負債やバグの早期検出は保守性向上の1つの手段 (How) である
	- 提案手法について述べる箇所では保守性向上のために早期検出という方法があることを明示すべき
- リポジトリマイニングを初期調査として行うのは良いが、その過程で問題が生じたときに対処しやすくするためにタイトルを変え、柔軟性を持たせるべき
- 「検出パターン」と説明するよりは、「保守性低下の兆候」とした方が厳密な議論ができる
- サービスの評価はコストなども影響するため、サービスは評価対象として含めない方がいい
- 「望ましいレベルの保守性」とは何かを明確にする
	- 反例を示し、「望ましくないレベルの保守性」を定義しても良い
- 保守性と進化可能性は異なる概念であるため、同じグループの言葉として扱うのは避ける
- アジャイル開発はフォーターフォール開発の対極にある概念ではなく、より広範な概念である
- ある概念に当てはまらない場合は「不完全な」などの形容詞を使い、印象をできる限り操作しないようにする
-  産業的な意味でのサプライチェーンとソフトウェア開発におけるサプライチェーンを区別して考える
- セキュリティ的な側面は議論せずに、品質に焦点を当てる
- 保守性が向上すると将来のバグ発生率が低下する (長期的なメリットがある)
- リファクタリングはバグ発生率に直接影響しないことに注意する
- 問題を早期に解決することがどのような利点をもたらすかを書く
- 保守性の低下は潜在的な問題であるため、その問題を解決するのが任意であるが、その問題は悪い影響を与えることがある。それを指摘する方が問題を解消する必要性を伝えやすい
- 全体の傾向などの抽象的な結果を述べるよりも具体的な指標の優劣を述べる
- 使いやすさの議論は評価に影響を及ぼすが、使いやすさを議論すると悪い結果について釈明しやすいため注意する
- ツールの使いやすさの違いはツール間のデザインの違いによるものであるため、評価対象としない
- 比較図を示すときは、フロー図よりも元の状態の差分を表す図を描くことで要点を強調する
- パターン化は多くの要素の抽象化を伴うので実施するかどうかを明言しない方がいい
	- この研究は共通の特性、原因、傾向を見つけたいのではないか？
- バグ発生率は本当に保守性の改善の程度を評価する上で重要な指標なのか？
- 予測される成果を増やすべき
- 計画は2か月ごとの間隔で示す
	- 研究のモデル化、調査、分析、評価で分ける
- 保守性について既存研究における問題点を示す
	  つまり、特定の時間における保守性の計測では継続的な改善に問題があることを指摘する
- 研究目的として、新たな開発プロセスを示すことを目的とする
	- つまり、既存のプロセスの問題点を改善したものを提示する



### 2.3.3. ヒストリカルシミュレーション
提案手法の予測性能を評価するために、過去のある時点に立ち戻り、将来の問題を予測するヒストリカルシミュレーションを実施する。具体的な手順は以下の通りである。

1. 評価対象プロジェクトの開発履歴を、訓練期間と評価期間に分割
2. 訓練期間のデータに対して、それぞれの異常検出アルゴリズムを適用
3. それぞれのアルゴリズムによって検出された、リスクの高いコード領域を特定
4. 評価期間において、それらの領域で実際にバグが発生したかを追跡
5. 予測性能を適合率、再現率、F1スコアで評価

さらに、プロジェクトの規模とそれぞれのアルゴリズムの性能の関係も分析し、どのような状況でどのアルゴリズムが最も効果的なを明らかにする。これにより、実際のプロジェクトにおいて品質低下検出アプローチを選択するためのガイドラインを提供する。

# 4. 研究スケジュール
1か月当たり3つのタスクに取り組む。1週間を1スプリントとして、1スプリント当たり1つのタスクを完了させることを目指す。スプリントが終了するたびに計画を見直す。予定よりも進捗が悪い場合は研究目標に基づいて優先順位を決め、優先順位の高いタスクを確実に完了させる。

- 4月
	- 研究対象リポジトリの選定基準の確立と候補リストの作成
	- PyDrillerを用いたコミット履歴データ収集システムの設計と実装
	- GitHub APIとPyGitHubを活用したイシュー・PR収集システムの設計と実装
- 5月
	- 研修対象リポジトリの最終選定とデータセットの収集
	- コード変更履歴の時系列データベースの構築
	- イシュー・PRデータとコミット履歴の関連付けシステムの実装
- 6月
	- 保守性低下の兆候の定義とカテゴリー化
	- 静的解析ツールとの連携機能の実装
	- コミットごとの品質メトリクスの収集
- 7月
	- Zスコアを用いた移動平均逸脱検出アルゴリズムの実装とテスト
	- CUSUMアルゴリズムによる変化点検出機能の実装とテスト
	- Isolation Forestによる複数のメトリクスに基づいた異常検出機能の実装とテスト
- 8月
	- 異常検出アルゴリズム間の比較実験
	- コード変更特性データと検出結果の相関分析
	- 中間発表に向けた初期結果の整理と分析
- 9月
	- 中間発表の実施と研究計画の見直し
	- (ヒストリカルシミュレーションの実施と初期評価)
	- 複数のプロジェクトにおける検出結果の比較分析
- 10月
	- プロジェクトの規模とアルゴリズムの性能の関係分析
	- それぞれのアルゴリズムにおけるパタメーターチューニングの必要性の検討
	- 早期検出による保守性向上効果の技術的評価
- 11月
	- プロジェクト固有の品質低下パターンの分析と一般化可能性の検証
	- アルゴリズム選択ガイドラインの作成
	- 研究成果の学術的な意義と応用可能性の整理
- 12月
	- 研究論文の執筆開始
	- 検出手法の改善点の整理と最終評価
	- 提案手法の他のプロジェクトへの適用可能性の検討
- 1月
	- 研究論文の完成と提出準備
	- 研究発表の準備
	- 今後の発展可能性の検討

研究を進める際は、毎週、週報を作成し、進捗を明文化する。