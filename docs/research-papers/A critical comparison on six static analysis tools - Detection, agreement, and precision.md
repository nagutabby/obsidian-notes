# A critical comparison on six static analysis tools - Detection, agreement, and precision
- 開発者は、静的解析ツール (SAT) を使用して、欠陥や技術的負債などのソースコードの潜在的な品質問題を制御する
- ツールベンダーは非常に多くのツールを考案しており、実践者が自分のニーズに最も適したツールを選択することを困難にしている
- これまで研究が行われてきたが、研究者が何に合意しているか、研究者の勧告はどのくらい正確であるのかについての知識が不足している
- Better Code Hub, CheckkStyle, Coverity Scan, FindBugs, PMD, SonarQubeの6つの一般的なSATの大規模な比較を提案することによって、このギャップを埋めることを目的としている
- 6つのSATを適用して47のJavaプロジェクトを分析する
- それらの合意を評価するために、それらが同じ問題を識別するかどうかを行レベルとクラスレベルで手動で分析することによって比較した
- 主要な結果は、ツール間の一致がほとんど、または全くなく、精度が低いことを示している
# はじめに
- 静的解析ツール (SAT) は、潜在的なソースコードの品質問題を発見するために、ソースコードを実行せずに分析する手段である
- これらのツールは、特に継続的インテグレーションパイプラインで使いやすくなるにつれて人気が高まっており、幅広い選択肢がある
- しかし、利用可能なツールの数が増加するにつれて、実践者が自分のニーズに最も適したツールを選択することが困難になる
- この選択プロセスで実践者を支援するために、研究者は既存のSATの能力を比較するための経験的研究を実施してきた
- 既存の研究では、3つの側面が十分に調査されていない
	1. 静的解析ツールによって実際に検出できるソース品質の問題
	2. 潜在的に問題があるとマークされたソースコードに関して異なるツール間の一致は何か
	3. 多種多様な利用可能なツールが推奨事項を提供する精度は何か
-  これらの側面に関する知識が改善されれば、実践者が使用するツールを選択する際に情報に基づいた決定を下せるだけでなく、研究者/ツールベンダーがツールを強化し、開発者に提供されるサポートのレベルを向上させることができる
- 本論文では、最も広く使用されている6つのSAT、すなわちSonarQube, Better Code Hub, Coverity Scan, FindBugs, PMD, およびCheckStyleの検出能力に関する大規模な経験的調査を提案
	- 具体的には、Qualitas Corpusデータセットからの47のプロジェクトのコーパスに対して検討されたツールを実行し、(1) ツールによって検出されたソースコードの品質問題の機能と分布を示し、(2) ツールによって与えられた推奨事項間の一致を行レベルで計算し、(3) ツールの精度を手動で計算
- 